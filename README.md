# ML Pipeline for Breast Cancer Diagnosis
Выполнил Калякин Тимофей в рамках экзамена по предмету Инжиниринг данных, МФТИ

## Содержание

* [Цель проекта](#цель-проекта)
* [Архитектура и схема пайплайна](#архитектура-и-схема-пайплайна)
* [Описание шагов пайплайна](#описание-шагов-пайплайна)
* [Инструкции по запуску](#инструкции-по-запуску)
* [Обоснование архитектурных решений](#обоснование-архитектурных-решений)
* [Интеграция с хранилищем](#интеграция-с-хранилищем)
* [Анализ ошибок и устойчивости](#анализ-ошибок-и-устойчивости)
* [Идеи и предложения по развитию](#идеи-и-предложения-по-развитию)
* [Скриншоты](#скриншоты)

---

## Цель проекта

Этот проект предназначен для автоматизации и оркестрации ETL-пайплайна машинного обучения для задачи диагностики рака молочной железы с использованием Apache Airflow и Python. Основная задача — построение предиктивной модели на основе датасета Breast Cancer Wisconsin Diagnostic, с автоматическим запуском всех этапов от загрузки данных до сохранения результатов.

---

### Анализ датасета и постановка задачи

Для построения модели используется датасет **Breast Cancer Wisconsin Diagnostic** (WDBC), содержащий клинические признаки опухолей молочной железы и метки «доброкачественная» или «злокачественная» опухоль.

**Задача машинного обучения:**
Построить бинарный классификатор, который по признакам диагностирует опухоль как злокачественную или доброкачественную, используя алгоритм логистической регрессии. Основной целью является максимизация качества классификации (Accuracy, Precision, Recall, F1-score) для поддержки диагностики заболеваний.

---
## Архитектура и схема пайплайна

### Структура пайплайна

Пайплайн автоматизирует процесс от загрузки данных до сохранения результатов модели. Включает следующие этапы:

1. **Загрузка данных** — импорт CSV, первичный анализ и проверка целостности.
2. **Предобработка данных** — очистка, нормализация, подготовка признаков.
3. **Обучение модели** — обучение логистической регрессии на подготовленных данных.
4. **Оценка модели** — вычисление ключевых метрик качества.
5. **Сохранение результатов** — запись модели и метрик с таймстампом.

---

### Схема пайплайна

```mermaid
graph LR
    A[Загрузка данных] --> B[Предобработка]
    B --> C[Обучение модели]
    C --> D[Оценка модели]
    D --> E[Сохранение результатов]
```

---

### Краткое описание шагов

* **Загрузка данных:** Считываем датасет из CSV, проверяем пропуски и структуру.
* **Предобработка:** Приводим данные к единому формату, нормализуем признаки.
* **Обучение:** Обучаем логистическую регрессию на тренировочных данных.
* **Оценка:** Вычисляем метрики Accuracy, Precision, Recall и F1-score для оценки качества модели.
* **Сохранение:** Сохраняем обученную модель и метрики в папку `results` с отметкой времени для последующего анализа.

---

## Описание шагов пайплайна

* **load\_data.py:** загружает CSV, делает базовый анализ, проверяет данные.
* **preprocess\_data.py:** чистит, нормализует, готовит признаки.
* **train\_model.py:** обучает логистическую регрессию.
* **evaluate\_model.py:** считает метрики классификации.
* **save\_results.py:** сохраняет модель и метрики в папку `results/run_<timestamp>`.

Все скрипты могут запускаться как независимо, так и внутри Airflow.

---

## Инструкции по запуску

### Запуск ETL скриптов локально:

```bash
python etl/load_data.py --config config/config.yaml
python etl/preprocess_data.py --config config/config.yaml
python etl/train_model.py --config config/config.yaml
python etl/evaluate_model.py --config config/config.yaml
python etl/save_results.py --config config/config.yaml
```

### Запуск через Airflow DAG

1. Запустить Airflow scheduler и webserver:

```bash
airflow scheduler
airflow webserver -p 8080
```

2. В UI Airflow найти DAG с id `ml_pipeline_breast_cancer`.

3. Запустить DAG вручную или настроить расписание.

4. Проверить логи и результаты в папке `results/run_<timestamp>`.

---

## Обоснование архитектурных решений

* Использование Airflow для надёжной оркестрации и мониторинга.
* Разделение логики на модули для удобства тестирования и поддержки.
* Сохранение результатов с временной меткой для версионирования артефактов.
* Настройка retries и timeout для устойчивости.
* Передача конфигурации через YAML для гибкости параметризации.

---

## Интеграция с хранилищем

Результаты сохраняются локально в структуре:

```
results/
  └─ run_YYYYMMDD_HHMMSS/
      ├─ model.pkl
      └─ metrics.json
```

Для облачного хранилища (например, Amazon S3) можно расширить функцию сохранения, реализовав загрузку с помощью boto3 с аутентификацией через AWS credentials.

---

## Анализ ошибок и устойчивости

Потенциальные точки отказа:

* Недоступность исходных данных (решено retry в Airflow и try-except в коде).
* Невалидные данные (реализована базовая валидация, проверки схемы).
* Ошибки обучения модели (обработка исключений, fallback, уведомления).
* Потеря соединения при сохранении (реализация retries, сохранение локально как резерв).

Airflow параметры, обеспечивающие устойчивость:

* `retries=2`, `retry_delay=timedelta(minutes=5)` на каждом таске.
* Таймауты выполнения (`execution_timeout`).
* Логирование каждого этапа в отдельные файлы.

---

## Идеи и предложения по развитию

* Добавить полноценную валидацию данных с использованием `pydantic` или `great_expectations`.
* Реализовать мониторинг качества модели с хранением метрик в базе.
* Интегрировать загрузку и выгрузку данных через облачные сервисы (S3, GDrive).
* Настроить алерты при сбоях через Slack или email.
* Автоматизировать обновление модели с помощью триггеров Airflow.

---

## Скриншоты

На скриншоте выбран успешно выполненный пайплайн. Также слева можно заметить два не выполненных, они были получены в процессе работы над кодом, доработки решения. 

![alt text](<Screenshot 2025-06-14 at 15.35.28.png>)
*Общий вид DAG в Airflow UI*


